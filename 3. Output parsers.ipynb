{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google AI ofrece una gama de modelos de chat avanzados que podemos usar en LangChain, permitiendo el uso de características como invocación de herramientas, streaming de tokens, y mucho más.\n",
    "\n",
    "Exploraremos cómo conectarnos a estos modelos, generar respuestas en diálogos, y cómo aprovechar las herramientas de Google para personalizar la seguridad y el rendimiento de nuestras aplicaciones de chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar los modelos de Google AI, necesitas obtener una clave API siguiendo estos pasos:\n",
    "\n",
    "    Visita Google AI  y genera una API key. \n",
    "    Guarda la clave para configurarla más adelante\n",
    "    \n",
    "https://ai.google.dev/gemini-api/docs/api-key?hl=es-419\n",
    "\n",
    "Alternativamente para usar mas capacidad usa Google Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Introduce tu clave API de Google AI: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior asegurará que tu clave API se mantenga segura y accesible sin estar directamente expuesta en el código. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para interactuar con los modelos de Google AI, necesitamos instalar el paquete de integración langchain-google-genai. Utiliza el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-google-genai\n",
    "# Instala en tu entorno de trabajo o a tu vs code,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar Respuestas con Google AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la integración instalada y la API key configurada, podemos instanciar un modelo de Google AI y generar una respuesta. Aquí usaremos el modelo Gemini 1.5-pro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AlexisBenitez\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore programmer. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg\n",
    "\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encadenar el Modelo con Plantillas de Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos mejorar la funcionalidad del modelo encadenándolo con plantillas de prompts. Esto permite adaptar el comportamiento del modelo de forma dinámica, por ejemplo, para traducciones entre diferentes idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich liebe das Programmieren. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Crear una plantilla de prompt para traducciones\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente útil que traduce {input_language} a {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Encadenar la plantilla con el modelo de Google AI\n",
    "chain = prompt | llm\n",
    "\n",
    "# Invocar la cadena con parámetros específicos MODIFICA AQUI\n",
    "ai_msg2 = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\", \n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(ai_msg2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de Seguridad en los Modelos Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos Gemini de Google AI tienen configuraciones de seguridad por defecto que ayudan a prevenir la generación de contenido dañino. Sin embargo, estas configuraciones pueden ser ajustadas para adaptarse mejor a las necesidades de tu aplicación.\n",
    "\n",
    "Por ejemplo, si estás recibiendo muchos “Safety Warnings” en tus respuestas, puedes modificar los umbrales de bloqueo para categorías específicas de contenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "\n",
    "# Desactivar el bloqueo para contenido peligroso\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En anterior código ajusta la configuración de seguridad para permitir contenido que normalmente podría estar bloqueado por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de Google ofrecen una solución robusta para construir aplicaciones de chat avanzadas, desde la configuración básica hasta la generación de respuestas y el uso de plantillas de prompts, hemos explorado cómo ajustar las configuraciones de seguridad para personalizar el comportamiento del modelo según las necesidades de tu aplicación.utilizando los modelos de Google AI con LangChain específicamente con Gemini."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
